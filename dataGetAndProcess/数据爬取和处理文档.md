# dataGetAndProcess

[toc]

## 文件树

dataGetAndProcess
│  readme.md
│  
├─CF
│      ItemCF.py
│      recomCD.py
│      UserCF.py
│      utils.py
│      
├─data
│      anime.json
│      comic.json
│      cos.json
│      novel.json
│      
├─data_acquisition
│  ├─BliBli_anime_get
│  │  │  anime.json
│  │  │  scrapy.cfg
│  │  │  
│  │  └─BliBli
│  │      │  items.py
│  │      │  middlewares.py
│  │      │  pipelines.py
│  │      │  settings.py
│  │      │  __init__.py
│  │      │  
│  │      └─spiders
│  │           │  spider_bl.py
│  │           └─ __init__.py
│  │              
│  ├─BliBli_comic_get
│  │  │  comic.json
│  │  │  scrapy.cfg
│  │  │  
│  │  └─BliBli
│  │      │  items.py
│  │      │  middlewares.py
│  │      │  pipelines.py
│  │      │  settings.py
│  │      │  __init__.py
│  │      │  
│  │      └─spiders
│  │              spider_bl.py
│  │              __init__.py
│  │              
│  ├─BliBli_cos_get
│  │  │  scrapy.cfg
│  │  │  
│  │  └─BliBli
│  │      │  items.py
│  │      │  middlewares.py
│  │      │  pipelines.py
│  │      │  settings.py
│  │      │  __init__.py
│  │      │  
│  │      └─spiders
│  │              spider_bl.py
│  │              __init__.py
│  │              
│  ├─BliBli_novel_get
│  │  │  novel.json
│  │  │  scrapy.cfg
│  │  │  
│  │  └─BliBli
│  │      │  items.py
│  │      │  middlewares.py
│  │      │  pipelines.py
│  │      │  settings.py
│  │      │  __init__.py
│  │      │  
│  │      └─spiders
│  │              spider_bl.py
│  │              __init__.py
│  │              
│  └─record
│          record.json
│          record.py
│          record1.json
│          record1.py
│          record2.json
│          record2.py
│          record3.json
│          
├─data_generation
│  │  getUniqueIdList.py
│  │  getUserImgIdList.py
│  │  historyGenerationDemo.py
│  │  imgBasedHistoryGeneration.py
│  │  userImgDescription.md
│  │  
│  ├─selectList
│  │      feizhaiSelectList.json
│  │      qingchunSelectList.json
│  │      xianchongSelectList.json
│  │      zhiguaiSelectList.json
│  │      zhongerSelectList.json
│  │      
│  ├─sysData
│  │      sysData.json
│  │      sysDataV1.json
│  │      sysDataV2.json
│  │      
│  └─uniqueList
│          feizhaiUniqueIdList.json
│          qingchunUniqueIdList.json
│          xianchongUniqueIdList.json
│          zhiguaiUniqueIdList.json
│          zhongerUniqueIdList.json
│          
├─data_insertion
│      animeIns.py
│      animeInsTest.py
│      comicIns.py
│      connectTest.py
│      cosplayIns.py
│      novelInsert.py
│      reTest.py
│      userHistoryInsert.py
│      userIns.py
│      userJsonInsertDB.py
│      wrongNovelInsert.py
│      
├─data_preProcess
│      anime_attr_len_analysis.py
│      anime_setId.py
│      anime_title_2json.py
│      comic_attr_len_analysis.py
│      comic_setId.py
│      comic_title_2json.py
│      cos_attr_len_analysis.py
│      cos_setId.py
│      cos_title_2json.py
│      novel_attr_len_analysis.py
│      novel_setId.py
│      novel_title_2json.py
│      readme.txt
│      
├─image
├─spark_analysis
│  │  anime_socre_count.py
│  │  anime_title.py
│  │  anime_type_count.py
│  │  comic_title.py
│  │  comic_type_count.py
│  │  cos_title.py
│  │  novel_socre_count.py
│  │  novel_title.py
│  │  novel_type_count.py
│  │  
│  └─src
│          stop_words.txt
│          
├─SQL
│      createTable.sql
│      
└─wordCloudAnalysis
    │  anime_title.py
    │  comic_title.py
    │  cosplay_title.py
    │  novel_title.py
    │  
    ├─image
    │      anime_title.png
    │      comic_title.png
    │      cos_title.png
    │      novel_title.png
    │      
    └─src
            stop_words.txt
            蒙版.png
            蒙版2.jpg
            蒙版3.png
            蒙版4.png
            

## CF

### UserCF.py

协同过滤算法，基于用户的推荐，放在首页

当用户进入网站的动漫/漫画/小说首页时，该算法根据当前用户，推荐与当前用户喜好类似的其他用户喜欢的物品

为加快运算速度，预处理user_item矩阵、user_sim_matrix矩阵。若不存在两个矩阵的json文件，则重新生成。

### ItemCF.py

协同过滤算法，基于物品的推荐，放在详情页

当用户点入某一部动漫/漫画/小说的详情页时，该算法根据当前用户与当前物品，推荐当前类别的其他物品

为加快运算速度，预处理user_item矩阵、item_sim_matrix矩阵。若不存在两个矩阵的json文件，则重新生成。

### recomCD.py

协同过滤算法，跨领域的推荐，复用UserCF.py代码，放在详情页

当用户点入某一部动漫/漫画/小说的详情页时，该算法寻找与该用户喜好类似的用户，推荐相似用户喜爱的其他类物品给目标用户

例如：进入动漫A的详情页，为用户推荐漫画与小说

### utils.py

存放三个推荐算法中用到的一些超参数，以及几个共用的工具函数

* `get_time_score()`：time decay（时间衰减），即不同时期的行为所占权重不同获取时间权重，很容易想到用户最近点击的物品喜好度应该更高一点
* `perfer_cal()`：综合用户评分、收藏、点赞、观看比例、时间戳得到一个综合评分
* `class AHP()`：层次分析法工具类，计算收藏、点赞、观看比例对综合评分的影响权重

## data_acquisition

该目录下包含数据挖掘所需模块，功能分别为从不同网站获取动漫、漫画、小说、cosplay数据，使用的数据挖掘框架为Scrapy

### BliBli_anime_get

该模块为动漫数据挖掘模块，通过对bilibili进行网络抓包分析，确定爬取网页的api接口，运行Scrapy爬取数据

#### spider_bl.py

该文件为主要爬虫文件，通过预先分析并设置的url对bilibili进行内容爬取，因为无法直接获取主站的html代码，故抓包分析后对b站api进行爬取，最终得到JSON格式的数据。此外，在该爬虫模块中对例如introduce等数据进行初步清洗，使用正则表达式去除爬取内容中"\n\t\r"等符号，对空白内容进行人为填充。

#### items.py

该文件定义爬取数据的存标题储格式及字段，包含番剧编号、媒体编号、标题、集数、是否完结、链接、封面图、真实发布日期、最近更新日期、追番、硬币、播放量、弹幕、评论数、评分、类型标签、简介这些字段

#### piplines.py

该文件处理主爬虫文件中生成的item并将其以json格式存储在data目录下

### BliBli_comic_get

该模块为漫画数据挖掘模块，通过对动漫之家进行网络抓包分析，确定爬取网页的url，运行Scrapy爬取数据

#### spider_bl.py

该文件为主要爬虫文件，通过预先分析并设置的url对动漫之家进行内容爬取，因动漫之家可以爬取html代码，故使用XPath对取回的response进行文本分析，获取有用信息。

#### items.py

该文件定义爬取数据的存标题储格式及字段，包含漫画编号、详情url、标题、漫画封面、最近更新标题、漫画作者、漫画类型、连载状态

#### piplines.py

该文件处理主爬虫文件中生成的item并将其以json格式存储在data目录下

### BliBli_novel_get

该模块为漫画数据挖掘模块，通过对SF轻小说进行网络抓包分析，确定爬取网页的url，运行Scrapy爬取数据

#### spider_bl.py

该文件为主要爬虫文件，通过预先分析并设置的url对SF轻小说进行内容爬取，因SF轻小说可以爬取html代码，故使用XPath对取回的response进行文本分析，获取有用信息。

#### items.py

该文件定义爬取数据的存标题储格式及字段，包含详情url、小说名、小说封面、小说评分、小说作者、小说类型、小说简介这些字段

#### piplines.py

该文件处理主爬虫文件中生成的item并将其以json格式存储在data目录下

### BliBli_cos_get

该模块为漫画数据挖掘模块，通过对Cosplay8进行网络抓包分析，确定爬取网页的url，运行Scrapy爬取数据

#### spider_bl.py

该文件为主要爬虫文件，通过预先分析并设置的url对Cosplay8进行内容爬取，因Cosplay8可以爬取html代码，故使用XPath对取回的response进行文本分析，获取有用信息。

#### items.py

该文件定义爬取数据的存标题储格式及字段，包含详情url、标题、封面这些字段

#### piplines.py

该文件处理主爬虫文件中生成的item并将其以json格式存储在data目录下

## data_generation
存放用户记录数据生成的算法、代码及所生成的用户记录数据

### getUniqueIdList.py

获取独占某一用户画像的作品id列表

### getUserImgIdList.py

获取某种用户画像对应的tag，再根据tag获取符合对应画像的作品id列表

### historyGenerationDemo.py

尝试生成用户记录的demo文件

### imgBasedHistoryGeneration.py

根据用户画像生成用户记录数据（初始数据与每日阅览数据）

### userImgDescription.md

用户画像描述

### selectList

存放符合各个用户画像对应tag的作品id列表
### zhongerSelectList.json
存放符合中二画像对应tag的作品id列表
### xianchongSelectList.json
存放符合现充画像对应tag的作品id列表
### feizhaiSelectList.json
存放符合肥宅画像对应tag的作品id列表
### zhiguaiSelectList.json
存放符合志怪画像对应tag的作品id列表
### qingchunSelectList.json
存放符合青春画像对应tag的作品id列表

## sysData

存放系统用户记录数据的json文件
### sysData.json
新生成数据默认存放位置
### sysDataV1.json
不考虑独占一特定画像作品情况下的记录生成文件（次新数据）
### sysDataV2.json
考虑独占一特定画像作品情况下的记录生成文件（最新数据）

### uniqueList

存放独占某一特定画像作品的id列表
### zhongerUniqueIdList.json
存放仅独占中二画像的作品id列表
### xianchongUniqueIdList.json
存放仅独占现充画像的作品id列表
### feizhaiUniqueIdList.json
存放仅独占肥宅画像的作品id列表
### zhiguaiUniqueIdList.json
存放仅独占志怪画像的作品id列表
### qingchunUniqueIdList.json
存放仅独占青春画像的作品id列表

## 用户画像描述
* 用户id: (Integer) 1000 - 1199

* 五种特定画像：中二、现充、肥宅、志怪、青春

#### 中二 1000 - 1039

```
anime:
热血，战斗，冒险，魔法，运动，机战，励志
comic: 
冒险，热血，格斗，魔法，励志，战争，竞技，武侠
novel:
魔幻，校园
```

#### 现充 1040 - 1079

```
anime:
搞笑，校园，治愈，职场，历史，美食
comic:
生活，职场，美食，欢乐向，战争，历史
novel:
都市
```

#### 肥宅 1080 - 1119

```
anime:
萌系，少女，穿越，偶像，音乐，泡面，萝莉
comic:
秀吉，宅系，萌系，福瑞，舰娘，音乐舞蹈
novel:
同人
```

#### 志怪 1120 - 1159

```
anime:
奇幻，科幻，架空，魔法，神魔，小说改，推理
comic:
奇幻，科幻，悬疑，魔法，神鬼，仙侠，惊悚，魔幻，恐怖
novel:
古风，玄幻，悬疑
```

#### 青春 1160 - 1199

```
anime:
日常，校园，恋爱，冒险，励志，社团
comic:
爱情，校园，纯爱，励志
novel:
校园，都市
```

## data_insertion
用于将所需要数据插入到数据库中，使用pymysql连接数据库进行插值，对于数据字段予以操作：适配数据库的字段类型，处理非法字符
### animeIns.py
根据生成的anime数据的json文件插入其中数据到数据库中
### animeInsTest.py 
根据生成的anime数据的json文件插入其中数据的单元测试
### comicIns.py
根据生成的comic数据的json文件插入其中数据到数据库中
### connectTest.py
连接数据库测试，本地（服务器）
### cosplayIns.py
根据生成的cosplay数据的json文件插入其中数据到数据库中
### novelInsert.py
根据生成的novel数据的json文件插入其中数据到数据库中
### reTest.py
正则化处理的测试，插入数据过程中，部分非法字符需要剔除
### userHistoryInsert.py
生成用户记录数据同时插入数据库中
### userIns.py
生成用户账户数据并将数据插入数据库中
### userJsonInsertDB.py
根据生成的存储用户记录数据的json文件将其中数据插入数据库中
### wrongNovelInsert.py
小说数据中对于部分简介字段中包含emoji表情的特殊数据的处理

## SQL
### createTable.sql
创建项目数据库的所有表单

## data_preProcess

### *_attr_len_analysis.py

为确定数据库字段最长长度，对所采集数据各字段进行长度分析

### *_setId.py

顺序为json数据打上id标签，便于存入数据库

### *_title_2json.py

将spark分析后得到的json文件进行重新格式化处理，转化为前端需要的格式

## spark_analysis

### *_score_count.py

使用spark对动漫、小说等评分进行大数据分析，得到各个评分段的评分数量

### *_type_count.py

使用spark对动漫、小说等类别进行大数据分析，得到各个类别在所有数据中出现频率

### *_title_count.py

先使用jieba进行中文分词，经过停词处理后，使用spark对分词及停词后的单词列表进行词频统计，以便传到前端进行词云图展示

## wordCountAnalysis

### *_title.py

先使用jieba进行中文分词，经过停词处理后，使用wordcloud对分词列表进行词频统计后生成词云图png文件到back的静态文件夹下，以便前端可以进行静态调用

### src

### stop_words.txt

停词列表

### 蒙版*.png

用于生成词云图时使用的蒙版图片

